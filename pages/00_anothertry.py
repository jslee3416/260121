import streamlit as st
import pandas as pd
import requests
import io
import urllib.parse

st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê°€ì´ë“œ", layout="wide")

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒŒì¼ ID
GOOGLE_FILE_ID = '15qLFBk-cWaGgGxe2sPz_FdgeYpquhQa4'

@st.cache_data(show_spinner=False)
def load_data_final(file_id):
    # êµ¬ê¸€ ëŒ€ìš©ëŸ‰ íŒŒì¼ ë³´ì•ˆ ê²½ê³  ìš°íšŒ ë¡œì§
    URL = "https://docs.google.com/uc?export=download"
    session = requests.Session()
    
    try:
        # 1ì°¨ ì‹œë„: í† í° í™•ì¸
        response = session.get(URL, params={'id': file_id}, stream=True)
        
        token = None
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                token = value
                break
        
        # 2ì°¨ ì‹œë„: í† í°ì´ ìˆë‹¤ë©´ í™•ì¸ í›„ ì¬ìš”ì²­
        if token:
            params = {'id': file_id, 'confirm': token}
            response = session.get(URL, params=params, stream=True)
        
        content = response.content
        
        # [í•´ê²° í•µì‹¬] ë‹¤ì–‘í•œ ì„¤ì •ìœ¼ë¡œ ë°ì´í„° ì½ê¸° ì‹œë„
        # ì¸ì½”ë”©: cp949(í•œê¸€), utf-8-sig
        # êµ¬ë¶„ì: sep=None (ìë™ ê°ì§€)
        for enc in ['cp949', 'utf-8-sig', 'euc-kr']:
            try:
                # ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´(str)ë¡œ ì½ì–´ì„œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
                df = pd.read_csv(
                    io.BytesIO(content),
                    encoding=enc,
                    sep=None,          # ì½¤ë§ˆ, íƒ­, ì„¸ë¯¸ì½œë¡  ìë™ ê°ì§€
                    engine='python',   # ìë™ ê°ì§€ë¥¼ ìœ„í•´ python ì—”ì§„ ì‚¬ìš©
                    usecols=[3, 8, 9, 18],
                    on_bad_lines='skip',
                    dtype=str
                )
                
                df.columns = ['status', 'name', 'category', 'address']
                
                # 'íì—…' ì œì™¸ í•„í„°ë§
                df = df[~df['status'].fillna('').str.contains("íì—…|ì·¨ì†Œ|ë§ì†Œ")].copy()
                
                if not df.empty:
                    return df
            except Exception:
                continue
                
        return "PARSE_ERROR"
        
    except Exception as e:
        return f"SYSTEM_ERROR: {str(e)}"

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ´ ì„œìš¸ì‹œ ì‹¤ì‹œê°„ ë§›ì§‘ ì¶”ì²œ")

with st.spinner('ë°ì´í„°ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ë¼ ìµœëŒ€ 15ì´ˆ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...'):
    data = load_data_final(GOOGLE_FILE_ID)

if data == "PARSE_ERROR":
    st.error("âŒ ë°ì´í„° í•´ì„ ì‹¤íŒ¨: íŒŒì¼ì˜ í˜•ì‹ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.info("íŒŒì¼ì´ CSV í˜•ì‹ì´ ë§ëŠ”ì§€, í˜¹ì€ íŒŒì¼ ë‚´ë¶€ì— íŠ¹ìˆ˜ë¬¸ìê°€ ë„ˆë¬´ ë§ì€ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
elif isinstance(data, str):
    st.error(data)
else:
    st.success(f"âœ… ì´ {len(data):,}ê°œì˜ ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")

    # ì—…ì¢… ì„ íƒ
    category_list = sorted(data['category'].dropna().unique().tolist())
    selected = st.selectbox("ğŸ± ìŒì‹ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + category_list)

    filtered = data if selected == "ì „ì²´" else data[data['category'] == selected]

    # ê²°ê³¼ ì¶œë ¥ (TOP 20)
    for i, row in filtered.head(20).iterrows():
        search_q = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']} í‰ì  ë¦¬ë·°")
        map_q = urllib.parse.quote(f"{row['name']} {row['address']}")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"### {row['name']}")
            st.caption(f"ğŸ“‚ {row['category']} | ğŸ“ {row['address']}")
        with col2:
            st.write("")
            st.markdown(f"[â­ í‰ì í™•ì¸](https://www.google.com/search?q={search_q})")
            st.markdown(f"[ğŸ“ ì§€ë„ë³´ê¸°](https://www.google.com/maps/search/?api=1&query={map_q})")
        st.divider()
