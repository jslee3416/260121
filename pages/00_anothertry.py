import streamlit as st
import pandas as pd
import requests
import io
import urllib.parse

st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê°€ì´ë“œ", layout="wide")

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒŒì¼ ID (ì‚¬ìš©ìë‹˜ íŒŒì¼)
GOOGLE_FILE_ID = '15qLFBk-cWaGgGxe2sPz_FdgeYpquhQa4'

@st.cache_data(show_spinner=False)
def load_data_from_gdrive(file_id):
    # ëŒ€ìš©ëŸ‰ íŒŒì¼ ë³´ì•ˆ ê²½ê³ ë¥¼ ë¬´ì‹œí•˜ê³  ê°•ì œ ë‹¤ìš´ë¡œë“œí•˜ëŠ” íŠ¹ìˆ˜ ì£¼ì†Œì…ë‹ˆë‹¤.
    # ì´ ì£¼ì†ŒëŠ” í† í° ì—†ì´ë„ ì§ì ‘ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
    direct_url = f"https://drive.google.com/uc?export=download&id={file_id}"
    
    try:
        # ë°ì´í„°ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ì§€ ì•Šê³  ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì½ì–´ ë©”ëª¨ë¦¬ ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
        response = requests.get(direct_url)
        response.raise_for_status()
        
        # íŒŒì¼ ë‚´ìš©
        content = response.content
        
        for enc in ['cp949', 'utf-8-sig', 'euc-kr']:
            try:
                df = pd.read_csv(
                    io.BytesIO(content),
                    encoding=enc,
                    usecols=[3, 8, 9, 18], # ìƒíƒœ, ì´ë¦„, ì—…ì¢…, ì£¼ì†Œ
                    on_bad_lines='skip',
                    low_memory=False,
                    dtype=str
                )
                df.columns = ['status', 'name', 'category', 'address']
                # íì—… ì œì™¸
                df = df[~df['status'].fillna('').str.contains("íì—…|ì·¨ì†Œ|ë§ì†Œ")].copy()
                return df
            except:
                continue
        return "ë°ì´í„° í•´ì„ ì‹¤íŒ¨"
    except Exception as e:
        return f"ì—°ê²° ì‹¤íŒ¨: {str(e)}"

st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ì¶”ì²œ (í´ë¼ìš°ë“œ ëª¨ë“œ)")

with st.spinner('êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ 149MB ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
    data = load_data_from_gdrive(GOOGLE_FILE_ID)

if isinstance(data, str):
    st.error(f"ì—ëŸ¬ ë°œìƒ: {data}")
    st.info("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê³µìœ  ì„¤ì •ì„ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì'ë¡œ ìœ ì§€í•´ ì£¼ì„¸ìš”.")
else:
    st.success(f"âœ… {len(data):,}ê°œì˜ ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ ë¡œë“œ ì™„ë£Œ!")
    
    # [ì—…ì¢… ì„ íƒ LoV]
    category_list = sorted(data['category'].dropna().unique().tolist())
    selected = st.selectbox("ğŸ± ìŒì‹ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + category_list)
    
    filtered = data if selected == "ì „ì²´" else data[data['category'] == selected]
    
    # [ìƒìœ„ 20ê°œ ì¶œë ¥]
    for i, row in filtered.head(20).iterrows():
        search_q = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']} í‰ì  ë¦¬ë·°")
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"### {row['name']}")
            st.caption(f"ğŸ“ {row['address']}")
        with col2:
            st.markdown(f"[â­ í‰ì í™•ì¸](https://www.google.com/search?q={search_q})")
        st.divider()
