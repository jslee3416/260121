import streamlit as st
import pandas as pd
import requests
import io
import urllib.parse

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê²€ìƒ‰ ì„œë¹„ìŠ¤", layout="wide")

# 2. êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒŒì¼ ID ë° URL ì„¤ì • (ë³´ë‚´ì£¼ì‹  ë§í¬ ë°˜ì˜)
GOOGLE_FILE_ID = '15qLFBk-cWaGgGxe2sPz_FdgeYpquhQa4'
DIRECT_URL = f'https://drive.google.com/uc?export=download&id={GOOGLE_FILE_ID}'

@st.cache_data(show_spinner=False)
def load_data_from_gdrive(url):
    try:
        # í´ë¼ìš°ë“œì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = requests.get(url)
        response.raise_for_status()
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ í•„ìš”í•œ 4, 9, 10ë²ˆì§¸ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        # 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ ì¸ë±ìŠ¤ëŠ” 3, 8, 9ì…ë‹ˆë‹¤.
        df = pd.read_csv(
            io.BytesIO(response.content),
            usecols=[3, 8, 9],
            encoding='cp949', # ê³µê³µë°ì´í„° í•œê¸€ ì¸ì½”ë”©
            low_memory=False
        )
        
        # ì»¬ëŸ¼ëª… í†µì¼
        df.columns = ['status', 'name', 'category']
        
        # [ì „ì²˜ë¦¬] íì—… ë°ì´í„° ì‚­ì œ ë° ì˜ì—… ì¤‘ì¸ ë°ì´í„°ë§Œ ìœ ì§€
        df = df[df['status'].fillna('').str.contains("ì˜ì—…|ì •ìƒ")].copy()
        df = df[~df['status'].fillna('').str.contains("íì—…")].copy()
        
        return df
    except Exception as e:
        return f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}"

# --- ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ---
st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ì •ë³´ ì„œë¹„ìŠ¤")
st.info("êµ¬ê¸€ í´ë¼ìš°ë“œì˜ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

# ë°ì´í„° ë¡œë”©
with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì•½ 10~15ì´ˆ ì†Œìš”)'):
    df = load_data_from_gdrive(DIRECT_URL)

if isinstance(df, str):
    st.error(df)
    st.warning("âš ï¸ êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒŒì¼ì˜ ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì'ë¡œ ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
else:
    st.success(f"âœ… ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ {len(df):,}ê°œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    # ì¹´í…Œê³ ë¦¬(ì—…íƒœ) ì„ íƒ ëª©ë¡ ìƒì„±
    categories = sorted(df['category'].dropna().unique().tolist())
    selected_category = st.selectbox("ğŸ¯ ìŒì‹ ì¢…ë¥˜(ì—…íƒœ)ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + categories)

    # í•„í„°ë§ ì ìš©
    final_df = df if selected_category == "ì „ì²´" else df[df['category'] == selected_category]

    st.subheader(f"ğŸ“ '{selected_category}' ê²€ìƒ‰ ê²°ê³¼ (ìµœìƒìœ„ 20ê°œ)")

    # ê²°ê³¼ ì¶œë ¥
    top_20 = final_df.head(20)
    
    if len(top_20) > 0:
        for i, row in top_20.iterrows():
            # êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ ìƒì„± (í‰ì  ë° í›„ê¸° í™•ì¸ìš©)
            search_query = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']} í‰ì ")
            google_url = f"https://www.google.com/search?q={search_query}"
            
            with st.container():
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(f"**{i+1}. {row['name']}**")
                    st.caption(f"ë¶„ë¥˜: {row['category']}")
                with col2:
                    st.markdown(f"[â­ í‰ì  í™•ì¸]({google_url})")
                st.divider()
    else:
        st.warning("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
