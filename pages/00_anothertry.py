import streamlit as st
import pandas as pd
import os
import urllib.parse

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê²€ìƒ‰ ì„œë¹„ìŠ¤", layout="wide")

# 2. ê²½ë¡œ ë¬¸ì œ í•´ê²°: ì‹¤í–‰ ì¤‘ì¸ .py íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê³„ì‚°í•˜ì—¬ CSV ìœ„ì¹˜ ì§€ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
CSV_PATH = os.path.join(current_dir, "restaurantinseoul.csv")

@st.cache_data
def load_and_process_data(path):
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(path):
        return "FILE_NOT_FOUND"

    # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•œ ì¸ì½”ë”© ìˆœì°¨ ì‹œë„
    encodings = ['cp949', 'utf-8-sig', 'euc-kr']
    
    for enc in encodings:
        try:
            container = []
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ í•„ìš”í•œ 4, 9, 10ë²ˆì§¸ ì»¬ëŸ¼ë§Œ 5ë§Œ ì¤„ì”© ëŠì–´ì„œ ì½ê¸°
            reader = pd.read_csv(
                path, 
                usecols=[3, 8, 9], 
                chunksize=50000, 
                low_memory=False, 
                encoding=enc
            )
            
            for chunk in reader:
                # ì»¬ëŸ¼ ì´ë¦„ í†µì¼ (ìƒíƒœ, ì‚¬ì—…ì¥ëª…, ì—…íƒœëª…)
                chunk.columns = ['status', 'name', 'category']
                
                # 'íì—…' ë°ì´í„° ì‚­ì œ ë° 'ì˜ì—…/ì •ìƒ' ë°ì´í„°ë§Œ ìœ ì§€
                filtered = chunk[chunk['status'].fillna('').str.contains("ì˜ì—…|ì •ìƒ")].copy()
                filtered = filtered[~filtered['status'].fillna('').str.contains("íì—…")].copy()
                
                container.append(filtered)
            
            if not container:
                return "EMPTY_DATA"
                
            return pd.concat(container, ignore_index=True)
            
        except (UnicodeDecodeError, ValueError):
            continue # ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„
        except Exception as e:
            return f"ERROR: {str(e)}"
            
    return "ENCODING_ERROR"

# --- ë©”ì¸ í™”ë©´ êµ¬ì„± ---
st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ì •ë³´ ì„œë¹„ìŠ¤")

# ì‚¬ì´ë“œë°” ë””ë²„ê¹… ì •ë³´
st.sidebar.header("ğŸ“ ì‹œìŠ¤í…œ ì •ë³´")
st.sidebar.info(f"ì•± ìœ„ì¹˜: {current_dir}")
st.sidebar.info(f"ì°¾ëŠ” íŒŒì¼: restaurantinseoul.csv")

# ë°ì´í„° ë¡œë“œ ë¡œì§ ì‹œì‘
if not os.path.exists(CSV_PATH):
    st.error("âŒ 'restaurantinseoul.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.markdown(f"""
    **í•´ê²° ë°©ë²•:**
    1. ì•„ë˜ ê²½ë¡œì— íŒŒì¼ì´ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”:
       `{CSV_PATH}`
    2. íŒŒì¼ëª…ì´ `restaurantinseoul.csv.csv`ì²˜ëŸ¼ í™•ì¥ìê°€ ì¤‘ë³µë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
    """)
else:
    with st.spinner('ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (ì•½ 149MB)'):
        result = load_and_process_data(CSV_PATH)

    if isinstance(result, str):
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {result}")
    else:
        df = result
        st.success(f"âœ… ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ {len(df):,}ê°œë¥¼ ë¡œë”©í–ˆìŠµë‹ˆë‹¤.")

        # 10ë²ˆì§¸ ì»¬ëŸ¼(category) ê¸°ë°˜ LoV (Selectbox) ìƒì„±
        # ê²°ì¸¡ì¹˜ë¥¼ ì œê±°í•˜ê³  ê³ ìœ ê°’ë§Œ ì¶”ì¶œí•˜ì—¬ ê°€ë‚˜ë‹¤ìˆœ ì •ë ¬
        categories = sorted(df['category'].dropna().unique().tolist())
        selected_category = st.selectbox("ğŸ¯ ìŒì‹ ì¢…ë¥˜(ì—…íƒœ)ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + categories)

        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if selected_category == "ì „ì²´":
            final_df = df
        else:
            final_df = df[df['category'] == selected_category]

        st.subheader(f"ğŸ“ '{selected_category}' ê²€ìƒ‰ ê²°ê³¼ (ìµœìƒìœ„ 20ê°œ)")

        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ (Top 20)
        top_20 = final_df.head(20)
        
        if len(top_20) > 0:
            for i, row in top_20.iterrows():
                # êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ ìƒì„±
                search_query = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']} í‰ì ")
                google_url = f"https://www.google.com/search?q={search_query}"
                
                with st.container():
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.write(f"**{i+1}. {row['name']}**")
                        st.caption(f"ë¶„ë¥˜: {row['category']}")
                    with col2:
                        # í‰ì  ë†’ì€ ìˆœ ì •ë ¬ì„ ìœ„í•´ êµ¬ê¸€ ê²€ìƒ‰ ì—°ê²°
                        st.markdown(f"[â­ í‰ì  í™•ì¸]({google_url})")
                    st.divider()
        else:
            st.warning("ì„ íƒí•œ ë¶„ë¥˜ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
