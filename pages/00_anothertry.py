import streamlit as st
import pandas as pd
import requests
import io
import urllib.parse

st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ë°ì´í„° ì§„ë‹¨", layout="wide")

GOOGLE_FILE_ID = '15qLFBk-cWaGgGxe2sPz_FdgeYpquhQa4'
DIRECT_URL = f'https://drive.google.com/uc?export=download&id={GOOGLE_FILE_ID}'

@st.cache_data(show_spinner=False)
def load_and_diagnose(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        
        # 1. ì¸ì½”ë”© ì‹œë„ ë° ì „ì²´ ë°ì´í„° ì½ê¸° (ìƒìœ„ 100ì¤„ë§Œ ìš°ì„  ë¶„ì„)
        df = pd.read_csv(io.BytesIO(response.content), encoding='cp949', low_memory=False)
        
        # 2. [ì§„ë‹¨ìš©] ëª¨ë“  ì»¬ëŸ¼ëª…ê³¼ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ë¦¬
        col_info = [{"ì¸ë±ìŠ¤": i, "ì»¬ëŸ¼ëª…": col, "ìƒ˜í”Œë°ì´í„°": str(df[col].iloc[0])} for i, col in enumerate(df.columns)]
        
        return df, col_info
    except Exception as e:
        return None, str(e)

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ë°ì´í„° ì§„ë‹¨ ë„êµ¬")

with st.spinner('ë°ì´í„° êµ¬ì¡°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
    df, info = load_and_diagnose(DIRECT_URL)

if df is None:
    st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {info}")
else:
    # --- 1ë‹¨ê³„: ë°ì´í„° êµ¬ì¡° ë³´ì—¬ì£¼ê¸° (ê°œë°œì ë„êµ¬ ì—­í• ) ---
    with st.expander("ğŸ” ë°ì´í„° ì‹¤ì œ êµ¬ì¡° í™•ì¸í•˜ê¸° (ì—¬ê¸°ë¥¼ í´ë¦­í•´ì„œ ì»¬ëŸ¼ ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”)"):
        st.write("ì´ í‘œë¥¼ ë³´ê³  'ì˜ì—…ìƒíƒœ', 'ì‚¬ì—…ì¥ëª…', 'ì—…íƒœëª…'ì´ ëª‡ ë²ˆ ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.table(info)
    
    # --- 2ë‹¨ê³„: ì•ˆì „í•œ ì»¬ëŸ¼ ì¶”ì¶œ ---
    # ì‚¬ìš©ìê°€ ë§í•œ 4, 9, 10ë²ˆì§¸(ì¸ë±ìŠ¤ 3, 8, 9)ë¥¼ ì‹œë„í•˜ë˜, 
    # ë°ì´í„°ê°€ 0ê°œë©´ í•„í„°ë§ì„ í’€ê³  ì›ë³¸ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    try:
        working_df = df.iloc[:, [3, 8, 9]].copy()
        working_df.columns = ['status', 'name', 'category']
        
        # í•„í„°ë§ ì „ ì›ë³¸ ë°ì´í„° ê±´ìˆ˜
        total_count = len(working_df)
        
        # 'íì—…'ì´ í¬í•¨ë˜ì§€ ì•Šì€ ê²ƒë§Œ í•„í„°ë§ (í•„í„°ë§ ì¡°ê±´ì„ ì•„ì£¼ ì•½í•˜ê²Œ ì„¤ì •)
        active_df = working_df[~working_df['status'].fillna('').str.contains("íì—…|ì·¨ì†Œ", na=False)].copy()
        
        st.success(f"âœ… ì „ì²´ {total_count:,}ê°œ ì¤‘ 'íì—…' ì œì™¸ {len(active_df):,}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # --- 3ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ì„ íƒ ë° ê²°ê³¼ ---
        categories = sorted(active_df['category'].dropna().unique().tolist())
        
        if not categories:
            st.warning("âš ï¸ ì¹´í…Œê³ ë¦¬(ì—…ì¢…) ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ ë²ˆí˜¸ê°€ ë§ëŠ”ì§€ ìœ„ í‘œì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        else:
            selected = st.selectbox("ğŸ¯ ì—…ì¢…ì„ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + categories)
            
            final_df = active_df if selected == "ì „ì²´" else active_df[active_df['category'] == selected]
            
            st.subheader(f"ğŸ“ '{selected}' ê²°ê³¼ (ìƒìœ„ 20ê°œ)")
            for i, row in final_df.head(20).iterrows():
                query = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']}")
                url = f"https://www.google.com/search?q={query}"
                
                col1, col2 = st.columns([4, 1])
                col1.write(f"**{row['name']}**")
                col1.caption(f"ìƒíƒœ: {row['status']} | ì—…ì¢…: {row['category']}")
                col2.markdown(f"[â­ êµ¬ê¸€ê²€ìƒ‰]({url})")
                st.divider()
                
    except Exception as e:
        st.error(f"ì»¬ëŸ¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ë°ì´í„°ì˜ ì»¬ëŸ¼ ìˆ˜ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
