import streamlit as st
import pandas as pd
import os
import urllib.parse

st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê²€ìƒ‰", layout="wide")

# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
CSV_PATH = r"C:\Users\jslee\Downloads\restaurantinseoul.csv"

@st.cache_data
def load_and_filter_data(path):
    if not os.path.exists(path):
        return None
    
    container = []
    # progress_barë¡œ ì§„í–‰ ìƒí™© ì‹œê°í™”
    progress_text = "ë°ì´í„°ë¥¼ í•œ ì¡°ê°ì”© ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."
    my_bar = st.progress(0, text=progress_text)
    
    # [í•µì‹¬] chunksizeë¥¼ ì§€ì •í•˜ì—¬ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì–´ ì½ìŒ (ë©”ëª¨ë¦¬ ê³¼ë¶€í•˜ ë°©ì§€)
    # 149MB ê¸°ì¤€ ì•½ 7~10ê°œ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
    total_chunks = 10 
    
    try:
        # í•„ìš”í•œ ì»¬ëŸ¼(3, 8, 9ë²ˆ)ë§Œ ì§€ì •í•´ì„œ ì½ê¸°
        reader = pd.read_csv(
            path, 
            usecols=[3, 8, 9], 
            chunksize=20000, 
            low_memory=False, 
            encoding='cp949' # í•œê¸€ ê¹¨ì§ ë°©ì§€ (í•„ìš” ì‹œ utf-8ë¡œ ë³€ê²½)
        )
        
        for i, chunk in enumerate(reader):
            # ì»¬ëŸ¼ëª… í†µì¼
            chunk.columns = ['status', 'name', 'category']
            
            # ì½ìë§ˆì 'íì—…' ë°ì´í„° ì‚­ì œ (ë°ì´í„° ë‹¤ì´ì–´íŠ¸)
            filtered_chunk = chunk[~chunk['status'].str.contains("íì—…", na=False)].copy()
            container.append(filtered_chunk)
            
            # ì§„í–‰ë°” ì—…ë°ì´íŠ¸
            progress = min((i + 1) / total_chunks, 1.0)
            my_bar.progress(progress, text=f"{progress_text} ({i+1}ë²ˆ ì¡°ê° ì²˜ë¦¬ ì¤‘)")
            
        my_bar.empty() # ì‘ì—… ì™„ë£Œ í›„ ì§„í–‰ë°” ì œê±°
        return pd.concat(container, ignore_index=True)
    
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# 2. ë°ì´í„° ì‹¤í–‰
df = load_and_filter_data(CSV_PATH)

if df is not None:
    st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ì •ë³´ ì„œë¹„ìŠ¤")
    st.caption(f"ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ {len(df):,}ê°œë¥¼ ë¡œë”© ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")

    # 3. LoV (10ë²ˆì§¸ ì»¬ëŸ¼ì´ì—ˆë˜ 'category')
    categories = sorted(df['category'].unique().tolist())
    selected_category = st.selectbox("ğŸ¯ ìŒì‹ ì¢…ë¥˜(ì—…íƒœ)ë¥¼ ì„ íƒí•˜ì„¸ìš”", categories)

    # 4. í•„í„°ë§ ë° ê²°ê³¼ ì¶œë ¥
    if selected_category:
        result_df = df[df['category'] == selected_category].head(20)
        
        st.subheader(f"ğŸ“ '{selected_category}' ê²€ìƒ‰ ê²°ê³¼ Top 20")
        
        for i, row in result_df.iterrows():
            # êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ ìƒì„±
            query = urllib.parse.quote(f"ì„œìš¸ {row['name']} {selected_category} í‰ì ")
            search_url = f"https://www.google.com/search?q={query}"
            
            with st.container():
                col1, col2 = st.columns([4, 1])
                col1.write(f"**{row['name']}**")
                col2.markdown(f"[â­ í‰ì í™•ì¸]({search_url})")
                st.divider() # êµ¬ë¶„ì„ 
else:
    st.info("ë°ì´í„° íŒŒì¼ì„ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
