import streamlit as st
import pandas as pd
import requests
import io
import urllib.parse

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ TOP 20", layout="wide")

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒŒì¼ ID ë° ì§ì ‘ ë‹¤ìš´ë¡œë“œ URL
GOOGLE_FILE_ID = '15qLFBk-cWaGgGxe2sPz_FdgeYpquhQa4'
DIRECT_URL = f'https://drive.google.com/uc?export=download&id={GOOGLE_FILE_ID}'

@st.cache_data(show_spinner=False)
def load_and_process_data(url):
    try:
        # í´ë¼ìš°ë“œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        response = requests.get(url)
        response.raise_for_status()
        content = response.content
        
        # [íŒŒì‹± í•´ê²°ì±…] ì—¬ëŸ¬ ì¸ì½”ë”© ë°©ì‹ì„ ì‹œë„í•˜ë©° ì˜¤ë¥˜ í–‰ì€ ê±´ë„ˆëœë‹ˆë‹¤.
        # 4ë²ˆì§¸(3:ìƒíƒœ), 9ë²ˆì§¸(8:ì´ë¦„), 10ë²ˆì§¸(9:ì—…ì¢…), 19ë²ˆì§¸(18:ì£¼ì†Œ) ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        for enc in ['utf-8-sig', 'cp949', 'euc-kr']:
            try:
                df = pd.read_csv(
                    io.BytesIO(content), 
                    encoding=enc, 
                    usecols=[3, 8, 9, 18],
                    on_bad_lines='skip', # íŒŒì‹± ì—ëŸ¬ ìœ ë°œí•˜ëŠ” ì˜ëª»ëœ í–‰ ë¬´ì‹œ
                    low_memory=False
                )
                
                # ì»¬ëŸ¼ëª… ì •ë¦¬
                df.columns = ['status', 'name', 'category', 'address']
                
                # [ìš”êµ¬ì‚¬í•­ 1] 4ë²ˆì§¸ ì»¬ëŸ¼ì—ì„œ 'íì—…'ì¸ ë°ì´í„° ì‚­ì œ
                # ìƒì„¸ì˜ì—…ìƒíƒœëª…ì— 'íì—…'ì´ ë“¤ì–´ê°„ ëª¨ë“  í–‰ ì œê±°
                df = df[~df['status'].fillna('').str.contains("íì—…|ì·¨ì†Œ|ë§ì†Œ")].copy()
                
                # ë°ì´í„°ê°€ ì¡´ì¬í•˜ë©´ ë°˜í™˜
                if not df.empty:
                    return df
            except Exception:
                continue
                
        return "ë°ì´í„° í˜•ì‹ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì¸ì½”ë”©ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
    except Exception as e:
        return f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}"

# --- ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ---
st.title("ğŸ´ ì„œìš¸ì‹œ ì‹¤ì‹œê°„ ë§›ì§‘ ì¶”ì²œ ê°€ì´ë“œ")
st.markdown("êµ¬ê¸€ ì§€ë„ì˜ í‰ì ê³¼ ë¦¬ë·° ì •ë³´ë¥¼ ì—°ë™í•˜ì—¬ ìƒìœ„ 20ê°œ ì‹ë‹¹ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")

with st.spinner('149MB ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ìµœì í™”í•˜ì—¬ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
    data = load_and_process_data(DIRECT_URL)

if isinstance(data, str):
    st.error(data)
    st.info("ğŸ’¡ êµ¬ê¸€ ë“œë¼ì´ë¸Œì˜ íŒŒì¼ ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì'ë¡œ ë˜ì–´ ìˆëŠ”ì§€ ê¼­ í™•ì¸í•´ ì£¼ì„¸ìš”.")
else:
    # [ìš”êµ¬ì‚¬í•­ 2] 10ë²ˆì§¸ ì»¬ëŸ¼(category) ê¸°ë°˜ìœ¼ë¡œ ì—…ì¢… ì„ íƒ LoV ìƒì„±
    category_list = sorted(data['category'].dropna().unique().tolist())
    
    col_select, col_info = st.columns([1, 2])
    with col_select:
        selected_category = st.selectbox("ğŸ± ì–´ë–¤ ìŒì‹ì„ ë“œì‹œê³  ì‹¶ë‚˜ìš”?", ["ì „ì²´ ë³´ê¸°"] + category_list)

    # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    filtered_df = data if selected_category == "ì „ì²´ ë³´ê¸°" else data[data['category'] == selected_category]

    st.markdown("---")
    st.subheader(f"ğŸ“ '{selected_category}' ì¶”ì²œ ë§›ì§‘ TOP 20")

    # [ìš”êµ¬ì‚¬í•­ 3] ìƒìœ„ 20ê°œ ì¶”ì¶œ ë° êµ¬ê¸€ë§µ/ë¦¬ë·° ì—°ë™
    top_20 = filtered_df.head(20)
    
    if len(top_20) > 0:
        for i, row in top_20.iterrows():
            # êµ¬ê¸€ ê²€ìƒ‰ ë° ì§€ë„ ì¿¼ë¦¬ ìƒì„±
            # ê²€ìƒ‰ì–´ ì˜ˆ: "ì„œìš¸ ë§ˆí¬êµ¬ ë§›ìˆëŠ”ì§‘ í•œì‹ í‰ì  ë¦¬ë·°"
            search_query = f"ì„œìš¸ {row['name']} {row['category']} í‰ì  ë¦¬ë·°"
            encoded_query = urllib.parse.quote(search_query)
            
            # êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ (í‰ì /ë¦¬ë·° í™•ì¸ìš©)
            google_search_url = f"https://www.google.com/search?q={encoded_query}"
            
            # êµ¬ê¸€ ë§µ ë§í¬ (ìœ„ì¹˜ í™•ì¸ìš©)
            map_query = urllib.parse.quote(f"{row['name']} {row['address']}")
            google_map_url = f"https://www.google.com/maps/search/?api=1&query={map_query}"
            
            with st.container():
                c1, c2 = st.columns([3, 1])
                with c1:
                    # 9ë²ˆì§¸ ì»¬ëŸ¼ì—ì„œ ì¶”ì¶œëœ ì‹ë‹¹ëª… í‘œê¸°
                    st.markdown(f"### {i+1}. {row['name']}")
                    st.write(f"ğŸ“‚ **ì—…ì¢…**: {row['category']} | âœ… **ìƒíƒœ**: {row['status']}")
                    st.caption(f"ğŸ“ **ì£¼ì†Œ**: {row['address'] if pd.notna(row['address']) else 'ì£¼ì†Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'}")
                
                with c2:
                    st.write("") # ìˆ˜ì§ ì •ë ¬ìš© ê³µë°±
                    # í‰ì  í™•ì¸ ë²„íŠ¼ (êµ¬ê¸€ ê²€ìƒ‰ ì—°ê²°)
                    st.markdown(f"""
                        <a href="{google_search_url}" target="_blank">
                            <button style="width:100%; padding:10px; background-color:#4285F4; color:white; border:none; border-radius:5px; cursor:pointer; margin-bottom:10px;">
                                â­ í‰ì /ë¦¬ë·° í™•ì¸
                            </button>
                        </a>
                    """, unsafe_allow_html=True)
                    
                    # ì§€ë„ ë³´ê¸° ë²„íŠ¼ (êµ¬ê¸€ ë§µ ì—°ê²°)
                    st.markdown(f"""
                        <a href="{google_map_url}" target="_blank">
                            <button style="width:100%; padding:10px; background-color:#34A853; color:white; border:none; border-radius:5px; cursor:pointer;">
                                ğŸ“ ìƒì„¸ ìœ„ì¹˜ ë³´ê¸°
                            </button>
                        </a>
                    """, unsafe_allow_html=True)
                st.divider()
    else:
        st.warning("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# í•˜ë‹¨ ì •ë³´
st.caption("ë°ì´í„° ì¶œì²˜: ì§€ë°©í–‰ì • ì¸í—ˆê°€ ë°ì´í„° (ì„œìš¸ì‹œ) | ê²€ìƒ‰ ê²°ê³¼ëŠ” êµ¬ê¸€ ì‹¤ì‹œê°„ ì •ë³´ì™€ ì—°ê²°ë©ë‹ˆë‹¤.")
