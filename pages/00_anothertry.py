import streamlit as st
import pandas as pd
import requests
import io
import urllib.parse

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê²€ìƒ‰ ì„œë¹„ìŠ¤", layout="wide")

# 2. êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒŒì¼ ID (ë³´ë‚´ì£¼ì‹  ID ìœ ì§€)
GOOGLE_FILE_ID = '15qLFBk-cWaGgGxe2sPz_FdgeYpquhQa4'
DIRECT_URL = f'https://drive.google.com/uc?export=download&id={GOOGLE_FILE_ID}'

@st.cache_data(show_spinner=False)
def load_data_from_gdrive(url):
    try:
        # í´ë¼ìš°ë“œì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = requests.get(url)
        response.raise_for_status()
        
        # [í•µì‹¬ ìˆ˜ì •] ì—¬ëŸ¬ ì¸ì½”ë”© ë°©ì‹ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.
        # ì—ëŸ¬ê°€ ë‚œë‹¤ë©´ utf-8-sig ë˜ëŠ” euc-krì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.
        encodings = ['utf-8-sig', 'cp949', 'euc-kr']
        
        for enc in encodings:
            try:
                # 4, 9, 10ë²ˆì§¸ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ì¸ë±ìŠ¤ 3, 8, 9)
                df = pd.read_csv(
                    io.BytesIO(response.content),
                    usecols=[3, 8, 9],
                    encoding=enc,
                    low_memory=False,
                    on_bad_lines='skip' # ê¹¨ì§„ í–‰ì´ ìˆë‹¤ë©´ ê±´ë„ˆëœë‹ˆë‹¤.
                )
                
                # ì»¬ëŸ¼ëª… í†µì¼
                df.columns = ['status', 'name', 'category']
                
                # [ì „ì²˜ë¦¬] íì—… ë°ì´í„° ì‚­ì œ ë° ì˜ì—… ì¤‘ì¸ ë°ì´í„°ë§Œ ìœ ì§€
                df = df[df['status'].fillna('').str.contains("ì˜ì—…|ì •ìƒ")].copy()
                df = df[~df['status'].fillna('').str.contains("íì—…")].copy()
                
                return df
            except (UnicodeDecodeError, LookupError):
                continue # ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„
                
        return "ëª¨ë“  ì¸ì½”ë”© ë°©ì‹(UTF-8, CP949 ë“±)ìœ¼ë¡œ ì½ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        return f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}"

# --- ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ---
st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ì •ë³´ ì„œë¹„ìŠ¤")
st.info("ğŸ’¡ êµ¬ê¸€ í´ë¼ìš°ë“œì—ì„œ 149MB ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤.")

# ë°ì´í„° ë¡œë”©
with st.spinner('í•œê¸€ ì¸ì½”ë”©ì„ ìµœì í™”í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
    df = load_data_from_gdrive(DIRECT_URL)

if isinstance(df, str):
    st.error(df)
    st.info("âš ï¸ íŒŒì¼ì˜ ì¸ì½”ë”© í˜•ì‹ì´ íŠ¹ìˆ˜í•˜ê±°ë‚˜ ë°ì´í„°ê°€ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
else:
    st.success(f"âœ… ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ {len(df):,}ê°œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    # ì¹´í…Œê³ ë¦¬(ì—…íƒœ) ì„ íƒ ëª©ë¡
    categories = sorted(df['category'].dropna().unique().tolist())
    selected_category = st.selectbox("ğŸ¯ ìŒì‹ ì¢…ë¥˜(ì—…íƒœ)ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + categories)

    # í•„í„°ë§ ë° ì¶œë ¥
    final_df = df if selected_category == "ì „ì²´" else df[df['category'] == selected_category]

    st.subheader(f"ğŸ“ '{selected_category}' ê²€ìƒ‰ ê²°ê³¼ (Top 20)")

    top_20 = final_df.head(20)
    
    if len(top_20) > 0:
        for i, row in top_20.iterrows():
            search_query = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']} í‰ì ")
            google_url = f"https://www.google.com/search?q={search_query}"
            
            col1, col2 = st.columns([4, 1])
            with col1:
                st.write(f"**{i+1}. {row['name']}**")
                st.caption(f"ë¶„ë¥˜: {row['category']}")
            with col2:
                st.markdown(f"[â­ í‰ì  í™•ì¸]({google_url})")
            st.divider()
    else:
        st.warning("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
