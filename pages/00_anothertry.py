import streamlit as st
import pandas as pd
import os
import urllib.parse

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê²€ìƒ‰ ì•±", layout="wide")

# [ë°©ë²• 1 ì ìš©] íŒŒì¼ì´ ì½”ë“œì™€ ê°™ì€ í´ë”ì— ìˆì„ ë•Œì˜ íŒŒì¼ëª…
CSV_PATH = "restaurantinseoul.csv"

@st.cache_data
def load_and_process_data(path):
    # 1. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(path):
        return "FILE_NOT_FOUND"

    # 2. ì¸ì½”ë”© í›„ë³´ ì„¤ì • (ê³µê³µë°ì´í„° í‘œì¤€ ì¸ì½”ë”© ìˆœì„œ)
    encodings = ['cp949', 'utf-8-sig', 'euc-kr']
    
    for enc in encodings:
        try:
            container = []
            # 3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ chunksize(ë‚˜ëˆ  ì½ê¸°)ì™€ usecols(ì»¬ëŸ¼ ì„ íƒ) ì ìš©
            # 4ë²ˆì§¸(3), 9ë²ˆì§¸(8), 10ë²ˆì§¸(9) ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
            reader = pd.read_csv(
                path, 
                usecols=[3, 8, 9], 
                chunksize=50000, 
                low_memory=False, 
                encoding=enc
            )
            
            for chunk in reader:
                # ì»¬ëŸ¼ ì´ë¦„ì´ í•œê¸€ì´ê±°ë‚˜ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê°•ì œ í†µì¼
                chunk.columns = ['status', 'name', 'category']
                
                # 4. [ë°ì´í„° ì •ì œ] íì—… ë°ì´í„° ì‚­ì œ ë° ì˜ì—… ë°ì´í„° í•„í„°ë§
                # fillna('')ë¥¼ í†µí•´ ê²°ì¸¡ì¹˜ë¡œ ì¸í•œ ì—ëŸ¬ ë°©ì§€
                filtered = chunk[chunk['status'].fillna('').str.contains("ì˜ì—…|ì •ìƒ")].copy()
                filtered = filtered[~filtered['status'].fillna('').str.contains("íì—…")].copy()
                
                container.append(filtered)
            
            # ì¡°ê°ë‚œ ë°ì´í„° í•©ì¹˜ê¸°
            full_df = pd.concat(container, ignore_index=True)
            return full_df
            
        except (UnicodeDecodeError, ValueError):
            continue # ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„
        except Exception as e:
            return f"ERROR: {str(e)}"
            
    return "ENCODING_ERROR"

# --- ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ---
st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ì •ë³´ ì„œë¹„ìŠ¤")

# í˜„ì¬ ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…)
if not os.path.exists(CSV_PATH):
    st.error(f"âŒ '{CSV_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.info("ğŸ’¡ **ì¡°ì¹˜ ë°©ë²•:** ì‹¤í–‰ ì¤‘ì¸ íŒŒì´ì¬ ì½”ë“œ(.py)ì™€ ê°™ì€ í´ë”ì— `restaurantinseoul.csv` íŒŒì¼ì„ ë³µì‚¬í•´ ë„£ì–´ì£¼ì„¸ìš”.")
else:
    with st.spinner('ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.'):
        result = load_and_process_data(CSV_PATH)

    if isinstance(result, str):
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {result}")
    else:
        df = result
        st.success(f"âœ… ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ {len(df):,}ê°œë¥¼ ë¡œë”©í–ˆìŠµë‹ˆë‹¤.")

        # 10ë²ˆì§¸ ì»¬ëŸ¼(category) ê¸°ë°˜ìœ¼ë¡œ ì„ íƒ ëª©ë¡(LoV) ìƒì„±
        categories = sorted(df['category'].dropna().unique().tolist())
        selected_category = st.selectbox("ğŸ¯ ìŒì‹ ì¢…ë¥˜(ì—…íƒœ)ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + categories)

        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì ìš©
        final_df = df if selected_category == "ì „ì²´" else df[df['category'] == selected_category]

        st.subheader(f"ğŸ“ '{selected_category}' ê²€ìƒ‰ ê²°ê³¼ (ìµœìƒìœ„ 20ê°œ)")

        # ê²°ê³¼ ì¶œë ¥ (Top 20)
        top_20 = final_df.head(20)
        
        if len(top_20) > 0:
            for i, row in top_20.iterrows():
                # êµ¬ê¸€ ê²€ìƒ‰ URL ìƒì„± (ì‹ë‹¹ì´ë¦„ + ì„œìš¸ + í‰ì )
                search_query = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']} í‰ì ")
                google_url = f"https://www.google.com/search?q={search_query}"
                
                with st.container():
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.write(f"**{i+1}. {row['name']}**")
                        st.caption(f"ë¶„ë¥˜: {row['category']}")
                    with col2:
                        st.markdown(f"[â­ í‰ì  í™•ì¸]({google_url})")
                    st.divider()
        else:
            st.warning("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
