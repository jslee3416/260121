import streamlit as st
import pandas as pd
import os
import urllib.parse


# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ ê²€ìƒ‰ ì„œë¹„ìŠ¤", layout="wide")

# 2. [ìˆ˜ì •í¬ì¸íŠ¸] ìš”ì²­í•˜ì‹  ë‹¤ìš´ë¡œë“œ í´ë” ê²½ë¡œë¡œ ì§ì ‘ ì„¤ì •
# ê²½ë¡œ ì•ì— rì„ ë¶™ì—¬ì•¼ ìœˆë„ìš° ê²½ë¡œì˜ ë°±ìŠ¬ë˜ì‹œ(\)ê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹ë©ë‹ˆë‹¤.
CSV_PATH = r"C:\Users\jslee\Downloads\restaurantinseoul.csv"

@st.cache_data
def load_and_process_data(path):
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(path):
        return "FILE_NOT_FOUND"

    # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•œ ì¸ì½”ë”© ìˆœì°¨ ì‹œë„
    encodings = ['cp949', 'utf-8-sig', 'euc-kr']
    
    for enc in encodings:
        try:
            container = []
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ í•„ìš”í•œ 4, 9, 10ë²ˆì§¸ ì»¬ëŸ¼ë§Œ 5ë§Œ ì¤„ì”© ëŠì–´ì„œ ì½ê¸°
            reader = pd.read_csv(
                path, 
                usecols=[3, 8, 9], 
                chunksize=50000, 
                low_memory=False, 
                encoding=enc
            )
            
            for chunk in reader:
                # ì»¬ëŸ¼ ì´ë¦„ í†µì¼ (ìƒíƒœ, ì‚¬ì—…ì¥ëª…, ì—…íƒœëª…)
                chunk.columns = ['status', 'name', 'category']
                
                # 'íì—…' ë°ì´í„° ì‚­ì œ ë° 'ì˜ì—…/ì •ìƒ' ë°ì´í„°ë§Œ ìœ ì§€
                filtered = chunk[chunk['status'].fillna('').str.contains("ì˜ì—…|ì •ìƒ")].copy()
                filtered = filtered[~filtered['status'].fillna('').str.contains("íì—…")].copy()
                
                container.append(filtered)
            
            if not container:
                return "EMPTY_DATA"
                
            return pd.concat(container, ignore_index=True)
            
        except (UnicodeDecodeError, ValueError):
            continue # ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„
        except Exception as e:
            return f"ERROR: {str(e)}"
            
    return "ENCODING_ERROR"

# --- ë©”ì¸ í™”ë©´ êµ¬ì„± ---
st.title("ğŸ´ ì„œìš¸ì‹œ ë§›ì§‘ ì •ë³´ ì„œë¹„ìŠ¤")

# ì‚¬ì´ë“œë°” ë””ë²„ê¹… ì •ë³´
st.sidebar.header("ğŸ“ ì‹œìŠ¤í…œ ê²½ë¡œ í™•ì¸")
st.sidebar.code(CSV_PATH)

# ë°ì´í„° ë¡œë“œ ë¡œì§ ì‹œì‘
if not os.path.exists(CSV_PATH):
    st.error(f"âŒ '{CSV_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.markdown(f"""
    **í•´ê²° ë°©ë²•:**
    1. ë‹¤ìš´ë¡œë“œ í´ë”(`C:\\Users\\jslee\\Downloads`)ì— `restaurantinseoul.csv` íŒŒì¼ì´ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.
    2. íŒŒì¼ í™•ì¥ìê°€ ìˆ¨ê²¨ì ¸ì„œ `restaurantinseoul.csv.csv`ì²˜ëŸ¼ ë˜ì–´ìˆì§€ëŠ” ì•Šì€ì§€ í™•ì¸í•˜ì„¸ìš”.
    3. í˜„ì¬ ì´ ì•±ì´ **ë¡œì»¬(ë‚´ ì»´í“¨í„°)**ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”. (í´ë¼ìš°ë“œ ë°°í¬ ì‹œ ì‚¬ìš©ìì˜ Cë“œë¼ì´ë¸ŒëŠ” ì ‘ê·¼ ë¶ˆê°€í•©ë‹ˆë‹¤.)
    """)
else:
    with st.spinner('ë‹¤ìš´ë¡œë“œ í´ë”ì—ì„œ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
        result = load_and_process_data(CSV_PATH)

    if isinstance(result, str):
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {result}")
    else:
        df = result
        st.success(f"âœ… ì˜ì—… ì¤‘ì¸ ì‹ë‹¹ {len(df):,}ê°œë¥¼ ë¡œë”©í–ˆìŠµë‹ˆë‹¤.")

        # 10ë²ˆì§¸ ì»¬ëŸ¼(category) ê¸°ë°˜ LoV ìƒì„±
        categories = sorted(df['category'].dropna().unique().tolist())
        selected_category = st.selectbox("ğŸ¯ ìŒì‹ ì¢…ë¥˜(ì—…íƒœ)ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + categories)

        # í•„í„°ë§ ì ìš©
        final_df = df if selected_category == "ì „ì²´" else df[df['category'] == selected_category]

        st.subheader(f"ğŸ“ '{selected_category}' ê²€ìƒ‰ ê²°ê³¼ (ìµœìƒìœ„ 20ê°œ)")

        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ (Top 20)
        top_20 = final_df.head(20)
        
        if len(top_20) > 0:
            for i, row in top_20.iterrows():
                # êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ ìƒì„±
                search_query = urllib.parse.quote(f"ì„œìš¸ {row['name']} {row['category']} í‰ì ")
                google_url = f"https://www.google.com/search?q={search_query}"
                
                with st.container():
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.write(f"**{i+1}. {row['name']}**")
                        st.caption(f"ë¶„ë¥˜: {row['category']}")
                    with col2:
                        st.markdown(f"[â­ í‰ì  í™•ì¸]({google_url})")
                    st.divider()
        else:
            st.warning("ì„ íƒí•œ ë¶„ë¥˜ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
