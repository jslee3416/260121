import streamlit as st
import pandas as pd
import urllib.parse
import os

st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ íŒŒì¸ë”", layout="wide")

DATA_FILE = "restaurants.csv"

@st.cache_data
def load_and_clean_data(file_name):
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(current_dir, file_name)
        
        if not os.path.exists(file_path):
            st.error(f"íŒŒì¼ ì—†ìŒ: {file_name}")
            return pd.DataFrame()

        # 1. ì¸ì½”ë”© ì‹œë„ (í•œê¸€ ê¹¨ì§ ë°©ì§€ ìµœì í™”)
        df = None
        for enc in ['cp949', 'utf-8-sig', 'utf-8', 'euc-kr']:
            try:
                # êµ¬ë¶„ì ìë™ ê°ì§€ ë° ê³µë°± ì œê±°(skipinitialspace) ì ìš©
                df = pd.read_csv(file_path, encoding=enc, sep=None, engine='python', skipinitialspace=True)
                if df is not None and not df.empty:
                    # ì»¬ëŸ¼ëª…ì˜ ì•ë’¤ ê³µë°± ì œê±°
                    df.columns = df.columns.str.strip()
                    break
            except:
                continue
        
        if df is None or df.empty:
            return pd.DataFrame()

        # [ë””ë²„ê¹… ì •ë³´] ì‚¬ì´ë“œë°”ì— ì‹¤ì œ ì½ì–´ì˜¨ ì»¬ëŸ¼ëª…ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        st.sidebar.info(f"ğŸ“‚ ê°ì§€ëœ ì»¬ëŸ¼ëª…: {df.columns.tolist()}")

        # 2. ì‹ë‹¹ëª… ì»¬ëŸ¼ íƒ€ê²ŸíŒ…
        # 'ì‹ë‹¹ëª…'ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¾ê³ , ì—†ìœ¼ë©´ ìœ ì‚¬í•œ ì´ë¦„ì„ ì°¾ìŠµë‹ˆë‹¤.
        target_name_col = next((c for c in df.columns if c == 'ì‹ë‹¹ëª…'), 
                          next((c for c in df.columns if 'ì‹ë‹¹' in c or 'ìƒí˜¸' in c), df.columns[0]))
        
        target_area_col = next((c for c in df.columns if 'ì§€ì—­' in c or 'ì£¼ì†Œ' in c), 
                          df.columns[1] if len(df.columns) > 1 else df.columns[0])
        
        target_menu_col = next((c for c in df.columns if 'ë©”ë‰´' in c), None)

        # ë°ì´í„° ì¬êµ¬ì„±
        rename_dict = {target_name_col: 'ìƒí˜¸', target_area_col: 'ì§€ì—­'}
        if target_menu_col:
            rename_dict[target_menu_col] = 'ë©”ë‰´'
            
        df = df[list(rename_dict.keys())].rename(columns=rename_dict)
        
        # 3. í–‰ì •êµ¬ì—­(êµ¬/ë™) ë¶„ë¦¬ ë¡œì§
        def split_region(x):
            if pd.isna(x): return "ë¯¸ë¶„ë¥˜", "ë¯¸ë¶„ë¥˜"
            parts = str(x).strip().split()
            gu = parts[0] if len(parts) > 0 else "ë¯¸ë¶„ë¥˜"
            dong = " ".join(parts[1:]) if len(parts) > 1 else "ì „ì²´"
            return gu, dong

        df[['êµ¬', 'ë™']] = df['ì§€ì—­'].apply(lambda x: pd.Series(split_region(x)))
        
        return df.dropna(subset=['ìƒí˜¸']).reset_index(drop=True)
        
    except Exception as e:
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

df = load_and_clean_data(DATA_FILE)

# 2. UI êµ¬ì„±
st.title("ğŸ´ ì„œìš¸ ë§›ì§‘ ì‹¤ì‹œê°„ í‰ì  ê°€ì´ë“œ")

if not df.empty:
    st.sidebar.success("âœ… 'ì‹ë‹¹ëª…' ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì—°ê²°í–ˆìŠµë‹ˆë‹¤!")
    
    # ì§€ì—­ í•„í„°
    gu_list = sorted(df['êµ¬'].unique())
    selected_gu = st.sidebar.selectbox("ìì¹˜êµ¬ ì„ íƒ", gu_list)
    
    dong_options = sorted(df[df['êµ¬'] == selected_gu]['ë™'].unique())
    selected_dong = st.sidebar.selectbox("ë²•ì •ë™ ì„ íƒ", ["ì „ì²´"] + dong_options)
    
    filtered_df = df[df['êµ¬'] == selected_gu]
    if selected_dong != "ì „ì²´":
        filtered_df = filtered_df[filtered_df['ë™'] == selected_dong]

    # ê²€ìƒ‰ ê¸°ëŠ¥
    search_query = st.sidebar.text_input("ğŸ” ì‹ë‹¹ ì´ë¦„ ê²€ìƒ‰", "")
    if search_query:
        filtered_df = filtered_df[filtered_df['ìƒí˜¸'].str.contains(search_query, na=False)]

    st.subheader(f"ğŸ“ {selected_gu} {selected_dong if selected_dong != 'ì „ì²´' else ''} ë§›ì§‘ ëª©ë¡")

    if not filtered_df.empty:
        # í˜ì´ì§€ë„¤ì´ì…˜
        rows_per_page = 15
        total_pages = max(len(filtered_df) // rows_per_page + (1 if len(filtered_df) % rows_per_page > 0 else 0), 1)
        current_page = st.number_input(f"í˜ì´ì§€ (1/{total_pages})", 1, total_pages, 1)
        
        start_idx = (current_page - 1) * rows_per_page
        page_data = filtered_df.iloc[start_idx : start_idx + rows_per_page].copy()

        # í…Œì´ë¸” ì¶œë ¥
        st.markdown("---")
        st.markdown("| ë²ˆí˜¸ | ì‹ë‹¹ëª… | ì§€ì—­(êµ¬/ë™) | ì‹¤ì‹œê°„ êµ¬ê¸€ í‰ì  ë§í¬ |")
        st.markdown("| :--- | :--- | :--- | :--- |")
        
        for i, (_, row) in enumerate(page_data.iterrows()):
            # êµ¬ê¸€ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•´ êµ¬+ë™+ì‹ë‹¹ëª… ì¡°í•©
            search_query = f"{row['êµ¬']} {row['ë™']} {row['ìƒí˜¸']}"
            google_url = f"https://www.google.com/maps/search/{urllib.parse.quote(search_query)}"
            
            menu_info = f" ({row['ë©”ë‰´']})" if 'ë©”ë‰´' in row and pd.notna(row['ë©”ë‰´']) else ""
            st.markdown(f"| {start_idx + i + 1} | **{row['ìƒí˜¸']}**{menu_info} | {row['êµ¬']} {row['ë™']} | [â­ í‰ì  í™•ì¸í•˜ê¸°]({google_url}) |")
    else:
        st.warning("ì„ íƒí•˜ì‹  ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì‹ë‹¹ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.info("íŒŒì¼ì˜ ì²« ì¤„ì— 'ì‹ë‹¹ëª…'ì´ë¼ëŠ” ì»¬ëŸ¼ ì œëª©ì´ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
