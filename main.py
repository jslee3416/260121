import streamlit as st
import pandas as pd
import urllib.parse
import os

st.set_page_config(page_title="ì„œìš¸ ë§›ì§‘ íŒŒì¸ë”", layout="wide")

# 1. íŒŒì¼ ê²½ë¡œ ì •ì˜
# Streamlit Cloud í™˜ê²½ì—ì„œ ê°€ì¥ ì•ˆì „í•œ ê²½ë¡œ ì§€ì • ë°©ì‹ì…ë‹ˆë‹¤.
DATA_FILE = "restaurants.csv"

@st.cache_data
def load_and_clean_data(file_name):
    try:
        # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ íŒŒì¼(main.py)ê³¼ ê°™ì€ í´ë”ì—ì„œ ì°¾ê¸°
        current_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(current_dir, file_name)
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ ìµœì¢… í™•ì¸
        if not os.path.exists(file_path):
            st.error(f"ì„œë²„ ë‚´ì— {file_name} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ì¸ì½”ë”© ë° êµ¬ë¶„ì ìë™ ê°ì§€ ë¡œì§ ê°•í™”
        df = None
        # ê³µê³µë°ì´í„°ëŠ” cp949ê°€ ê°€ì¥ ë§ìœ¼ë¯€ë¡œ ë¨¼ì € ì‹œë„í•©ë‹ˆë‹¤.
        for enc in ['cp949', 'utf-8', 'euc-kr']:
            try:
                # sep=None, engine='python'ì€ ì‰¼í‘œ/íƒ­ ë“±ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ì¤ë‹ˆë‹¤.
                df = pd.read_csv(file_path, encoding=enc, sep=None, engine='python')
                if df is not None and not df.empty and len(df.columns) > 1:
                    break
            except:
                continue
        
        if df is None or df.empty:
            st.error("íŒŒì¼ì„ ì½ì—ˆìœ¼ë‚˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # [ì»¬ëŸ¼ ë§¤ì¹­] ì‹¤ì œ íŒŒì¼ ë‚´ ì»¬ëŸ¼ëª…ê³¼ ì—°ê²°
        # ì œê³µí•´ì£¼ì‹  ì •ë³´ ê¸°ì¤€: 'ì‹ë‹¹ëª…', 'ì§€ì—­ëª…', 'ëŒ€í‘œë©”ë‰´ëª…'
        name_map = {
            'ì‹ë‹¹ëª…': 'ìƒí˜¸',
            'ì§€ì—­ëª…': 'ì§€ì—­',
            'ëŒ€í‘œë©”ë‰´ëª…': 'ëŒ€í‘œë©”ë‰´'
        }
        
        # ì‹¤ì œ íŒŒì¼ì— ìˆëŠ” ì»¬ëŸ¼ë§Œ ê³¨ë¼ë‚´ê¸°
        existing_cols = [c for c in name_map.keys() if c in df.columns]
        df = df[existing_cols].rename(columns=name_map).copy()
        
        # í–‰ì •êµ¬ì—­(êµ¬/ë™) ë¶„ë¦¬ í•¨ìˆ˜
        def split_region(x):
            if pd.isna(x): return "ë¯¸ë¶„ë¥˜", "ë¯¸ë¶„ë¥˜"
            parts = str(x).split()
            gu = parts[0] if len(parts) > 0 else "ë¯¸ë¶„ë¥˜"
            # êµ¬ ë’¤ì— ì˜¤ëŠ” ëª¨ë“  ê¸€ìë¥¼ ë™ìœ¼ë¡œ í•©ì¹¨
            dong = " ".join(parts[1:]) if len(parts) > 1 else "ì „ì²´"
            return gu, dong

        # ì§€ì—­ ì»¬ëŸ¼ì´ ìˆì„ ë•Œë§Œ ë¶„ë¦¬ ì‹¤í–‰
        if 'ì§€ì—­' in df.columns:
            df[['êµ¬', 'ë™']] = df['ì§€ì—­'].apply(lambda x: pd.Series(split_region(x)))
        else:
            # ì§€ì—­ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì„ì‹œ ë°ì´í„° ìƒì„±
            df['êµ¬'] = "ì„œìš¸ì „ì²´"
            df['ë™'] = "ì „ì²´"
        
        return df.reset_index(drop=True)
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# ë°ì´í„° ë¡œë“œ ì‹¤í–‰
df = load_and_clean_data(DATA_FILE)

# 2. UI êµ¬ì„±
st.title("ğŸ´ ì„œìš¸ ë§›ì§‘ ì‹¤ì‹œê°„ í‰ì  ê°€ì´ë“œ")
st.markdown("---")

if not df.empty:
    st.sidebar.success("âœ… ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
    
    # ì‚¬ì´ë“œë°” í•„í„°
    st.sidebar.header("ğŸ“ ì§€ì—­ í•„í„°")
    gu_list = sorted(df['êµ¬'].unique())
    selected_gu = st.sidebar.selectbox("ìì¹˜êµ¬ ì„ íƒ", gu_list)
    
    dong_options = sorted(df[df['êµ¬'] == selected_gu]['ë™'].unique())
    selected_dong = st.sidebar.selectbox("ë²•ì •ë™ ì„ íƒ", ["ì „ì²´"] + dong_options)
    
    # ë°ì´í„° í•„í„°ë§
    filtered_df = df[df['êµ¬'] == selected_gu]
    if selected_dong != "ì „ì²´":
        filtered_df = filtered_df[filtered_df['ë™'] == selected_dong]

    # ê²€ìƒ‰ ê¸°ëŠ¥
    search_query = st.sidebar.text_input("ğŸ” ì‹ë‹¹ ì´ë¦„ ê²€ìƒ‰", "")
    if search_query:
        filtered_df = filtered_df[filtered_df['ìƒí˜¸'].str.contains(search_query, na=False)]

    st.subheader(f"ğŸ“ {selected_gu} {selected_dong if selected_dong != 'ì „ì²´' else ''} ë§›ì§‘ ëª©ë¡")
    st.write(f"ê²€ìƒ‰ ê²°ê³¼: ì´ **{len(filtered_df)}**ê°œ")

    # 3. ê²°ê³¼ ì¶œë ¥ (í‘œ í˜•ì‹ ë° êµ¬ê¸€ë§µ ë§í¬)
    if not filtered_df.empty:
        rows_per_page = 15
        total_pages = max(len(filtered_df) // rows_per_page + (1 if len(filtered_df) % rows_per_page > 0 else 0), 1)
        current_page = st.number_input(f"í˜ì´ì§€ (1/{total_pages})", 1, total_pages, 1)
        
        start_idx = (current_page - 1) * rows_per_page
        page_data = filtered_df.iloc[start_idx : start_idx + rows_per_page].copy()

        def make_google_link(row):
            search_text = f"{row['êµ¬']} {row['ë™']} {row['ìƒí˜¸']}"
            return f"https://www.google.com/maps/search/{urllib.parse.quote(search_text)}"

        st.markdown("---")
        # í…Œì´ë¸” í—¤ë”
        st.markdown("| ë²ˆí˜¸ | ì‹ë‹¹ëª… | ëŒ€í‘œë©”ë‰´ | ì‹¤ì‹œê°„ êµ¬ê¸€ í‰ì  ë§í¬ |")
        st.markdown("| :--- | :--- | :--- | :--- |")
        
        for i, (_, row) in enumerate(page_data.iterrows()):
            menu = row['ëŒ€í‘œë©”ë‰´'] if pd.notna(row['ëŒ€í‘œë©”ë‰´']) else "-"
            google_url = make_google_link(row)
            st.markdown(f"| {start_idx + i + 1} | **{row['ìƒí˜¸']}** | {menu} | [â­ í‰ì /ë¦¬ë·° í™•ì¸í•˜ê¸°]({google_url}) |")
    else:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ì‹ë‹¹ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.error("íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. CSV íŒŒì¼ ë‚´ë¶€ì˜ ì»¬ëŸ¼ëª…('ì‹ë‹¹ëª…', 'ì§€ì—­ëª…')ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
